output_path: outputs/seq2seq/
tensorboard_logdir: ${output_path}/tensorboard_logdir
log_dir: ${output_path}
debug: false
hydra:
    run:
      dir: ${output_path}
    job_logging:
      handlers:
        file:
          mode: 'w'
dataset:
  dataset_path: ../../data/data.txt
  dataset_url: https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt
  source_language: ru
  target_language: en
  source_language_index: 1
  target_language_index: 0
  train_dataset_path: ../../data/train_data.txt
  val_dataset_path: ../../data/val_data.txt
  test_dataset_path: ../../data/test_data.txt
  train_size: 0.8
  val_size: 0.15
  test_size: 0.05
model:
  enc_emb_dim: 128
  dec_emb_dim: 128
  enc_hid_dim: 256
  dec_hid_dim: 256
  attn_dim: 128
  enc_dropout: 0.5
  dec_dropout: 0.5
  pretrained_embedding: none
  rnn_type: gru
  bidirectional: false
train:
  batch_size: 16
  n_epoch: 40
  device: cuda
  learning_rate: 0.0008
preprocessing:
  spacy_tokenizer:
    ru: ru_core_news_lg
    en: en_core_web_lg
